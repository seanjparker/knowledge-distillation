{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QHeNYIJRpSdN",
    "outputId": "7e6a8634-55f1-456d-b2cb-5ebf517df6ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "6bd10102191f4d57b7b29a03d0b774df",
      "0078465cbd9f446880ddbee680d4796e",
      "9ba0847785674caa983f98654ae6f326",
      "fadfa1710b2b4d46afab50d23c04c30b",
      "2e5f050fe8dc457782d0ea2b1d812677",
      "f128a054172c4c52bfaf4e3b10d4c452",
      "146b2aec3c83444c8d3cb319347e49d4",
      "7104988653034cfe90129737fca16688"
     ]
    },
    "id": "ppgs4aCPpSdR",
    "outputId": "68212292-1d15-41d8-cf88-6293821e4eaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./datasets/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd10102191f4d57b7b29a03d0b774df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/cifar-10-python.tar.gz to ./datasets\n"
     ]
    }
   ],
   "source": [
    "cifar_class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "cifar = torchvision.datasets.CIFAR10('./datasets', train=True, download=True,\n",
    "                                     transform=torchvision.transforms.Compose([\n",
    "                                         torchvision.transforms.ToTensor(),\n",
    "                                         torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                                     ]))\n",
    "\n",
    "train, test = torch.utils.data.random_split(cifar, [40000, 10000])\n",
    "batch_size = 256\n",
    "train_dataset = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "runoulM7pSdS"
   },
   "outputs": [],
   "source": [
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "def calc_accuracy(model):\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_dataset):\n",
    "            imgs, true_labels = data[0].to(device), data[1].to(device)\n",
    "            preds = model(imgs)\n",
    "            pred_class = torch.argmax(preds, dim=1)\n",
    "            incorrect = torch.count_nonzero(pred_class - true_labels)\n",
    "            correct += len(true_labels) - incorrect\n",
    "\n",
    "    print(f'test accuracy: {(correct * 100) / len(test):.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjNEs71Ju9aN"
   },
   "source": [
    "# ResNet-18 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "-RW9rIlspSdS"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "teacher_model = ResNet(BasicBlock, [2, 2, 2, 2]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkpNnwPE8cVV",
    "outputId": "6c8af9e3-5dfe-404d-f54c-c043dc679d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
      "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
      "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
      "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
      "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
      "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
      "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
      "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
      "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
      "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
      "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
      "           Linear-49                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 11.25\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 53.89\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "test accuracy: 82.470%\n"
     ]
    }
   ],
   "source": [
    "teacher_model.load_state_dict(torch.load('./models/cifar_teacher_0.pt'))\n",
    "print(summary(teacher_model, (3, 32, 32)))\n",
    "calc_accuracy(teacher_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7EFp_UUpSdS"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(teacher_model.parameters(), lr=0.01)\n",
    "teacher_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "time_s = lambda: time.time()\n",
    "for ep in range(epochs):\n",
    "    start_time = time_s()\n",
    "    ep_loss = 0.0\n",
    "    correct = 0\n",
    "    for i, (imgs, labels) in enumerate(train_dataset):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = teacher_model(imgs)\n",
    "        loss = teacher_loss_fn(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred_class = torch.argmax(preds, dim=1).to(device)\n",
    "        correct += len(labels) - torch.count_nonzero(pred_class - labels)\n",
    "        \n",
    "        ep_loss += loss.detach().item()\n",
    "\n",
    "    print(f'epoch: {ep+1}, loss: {ep_loss / len(train_dataset):.4f}, train acc: {(correct * 100.0) / len(train):.3f}%, time: {(time_s() - start_time):.2f}s')\n",
    "\n",
    "calc_accuracy(teacher_model)\n",
    "\n",
    "torch.save(teacher_model.state_dict(), './models/cifar_teacher.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgfbU6JGpSdT"
   },
   "source": [
    "# Building Teacher and Student models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "Og0hg8AxpSdT"
   },
   "outputs": [],
   "source": [
    "# Softmax with temperature\n",
    "# -- Adapted from PyTorch Softmax layer\n",
    "# -- See: https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Softmax\n",
    "class SoftmaxT(nn.Module):\n",
    "    def __init__(self, temperature, dim = 1) -> None:\n",
    "        super(SoftmaxT, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.dim = dim\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        self.__dict__.update(state)\n",
    "        if not hasattr(self, 'dim'):\n",
    "            self.dim = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        return torch.nn.functional.softmax(input / self.temperature, self.dim, _stacklevel=5)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return 'dim={dim}'.format(dim=self.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C7Yfeq-GpSdT",
    "outputId": "f58682ce-3817-428c-8d32-14f7775b3535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
      "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
      "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
      "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
      "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
      "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
      "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
      "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
      "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
      "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
      "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
      "           Linear-49                   [-1, 10]           5,130\n",
      "           ResNet-50                   [-1, 10]               0\n",
      "         SoftmaxT-51                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 11.25\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 53.89\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 30, 30]             448\n",
      "              ReLU-2           [-1, 16, 30, 30]               0\n",
      "         MaxPool2d-3           [-1, 16, 15, 15]               0\n",
      "            Conv2d-4           [-1, 32, 13, 13]           4,640\n",
      "              ReLU-5           [-1, 32, 13, 13]               0\n",
      "         MaxPool2d-6             [-1, 32, 6, 6]               0\n",
      "           Flatten-7                 [-1, 1152]               0\n",
      "            Linear-8                   [-1, 32]          36,896\n",
      "              ReLU-9                   [-1, 32]               0\n",
      "          Dropout-10                   [-1, 32]               0\n",
      "           Linear-11                   [-1, 10]             330\n",
      "         SoftmaxT-12                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 42,314\n",
      "Trainable params: 42,314\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.35\n",
      "Params size (MB): 0.16\n",
      "Estimated Total Size (MB): 0.52\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "temperature = 5\n",
    "\n",
    "# Create a new model with softmax temperature\n",
    "teacher_model_w_temperature = torch.nn.Sequential(\n",
    "    teacher_model,\n",
    "    SoftmaxT(temperature)\n",
    ").to(device)\n",
    "print(summary(teacher_model_w_temperature, (3, 32, 32)))\n",
    "\n",
    "# Create the student model\n",
    "student_model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, kernel_size=(3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "    nn.Conv2d(16, 32, kernel_size=(3, 3)),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(1152, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.1),\n",
    "    nn.Linear(32, 10),\n",
    "    SoftmaxT(temperature)\n",
    ").to(device)\n",
    "print(summary(student_model, (3, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5SEiKzQDpSdT",
    "outputId": "112695ae-9db1-413f-c92a-226fd60c121e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 1.21e-02, train acc: 33.000%, time: 16.03s\n",
      "epoch: 2, loss: 1.02e-02, train acc: 44.335%, time: 15.96s\n",
      "epoch: 3, loss: 9.12e-03, train acc: 48.727%, time: 15.83s\n",
      "epoch: 4, loss: 8.24e-03, train acc: 51.757%, time: 15.87s\n",
      "epoch: 5, loss: 7.42e-03, train acc: 54.970%, time: 15.99s\n",
      "epoch: 6, loss: 6.86e-03, train acc: 56.885%, time: 16.03s\n",
      "epoch: 7, loss: 6.33e-03, train acc: 58.537%, time: 16.09s\n",
      "epoch: 8, loss: 5.96e-03, train acc: 59.702%, time: 15.85s\n",
      "epoch: 9, loss: 5.67e-03, train acc: 60.822%, time: 15.97s\n",
      "epoch: 10, loss: 5.36e-03, train acc: 61.745%, time: 16.06s\n",
      "epoch: 11, loss: 5.16e-03, train acc: 62.618%, time: 15.98s\n",
      "epoch: 12, loss: 4.95e-03, train acc: 63.170%, time: 16.13s\n",
      "epoch: 13, loss: 4.71e-03, train acc: 64.010%, time: 16.12s\n",
      "epoch: 14, loss: 4.53e-03, train acc: 64.955%, time: 16.00s\n",
      "epoch: 15, loss: 4.35e-03, train acc: 65.185%, time: 16.45s\n",
      "epoch: 16, loss: 4.25e-03, train acc: 65.675%, time: 16.41s\n",
      "epoch: 17, loss: 4.06e-03, train acc: 66.228%, time: 16.44s\n",
      "epoch: 18, loss: 3.97e-03, train acc: 66.562%, time: 16.27s\n",
      "epoch: 19, loss: 3.86e-03, train acc: 67.027%, time: 16.30s\n",
      "epoch: 20, loss: 3.78e-03, train acc: 67.362%, time: 16.43s\n",
      "test accuracy: 63.310%\n"
     ]
    }
   ],
   "source": [
    "# KD from teacher using whole dataset\n",
    "student_model.apply(weight_reset)\n",
    "student_optimizer = torch.optim.Adam(student_model.parameters(), lr=0.001)\n",
    "student_loss_fn = nn.CrossEntropyLoss()\n",
    "distillation_loss_fn = torch.nn.KLDivLoss()\n",
    "\n",
    "kd_epochs = 20\n",
    "time_s = lambda: time.time()\n",
    "for ep in range(kd_epochs):\n",
    "    ep_loss = 0.0\n",
    "    correct = 0\n",
    "    start_time = time_s()\n",
    "    for i, data in enumerate(train_dataset):\n",
    "        imgs, true_labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        student_optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass of the teacher with input\n",
    "        with torch.no_grad():\n",
    "            teacher_output = teacher_model_w_temperature(imgs).to(device)\n",
    "\n",
    "        # Forward pass of the student\n",
    "        student_output = student_model(imgs).to(device)\n",
    "\n",
    "        # Calculate loss\n",
    "        student_loss = student_loss_fn(student_output, true_labels)\n",
    "        distill_loss = distillation_loss_fn(teacher_output, student_output)\n",
    "        loss = alpha * student_loss + (1 - alpha) * distill_loss\n",
    "\n",
    "        loss.backward()\n",
    "        student_optimizer.step()\n",
    "\n",
    "        pred_class = torch.argmax(student_output, dim=1).to(device)\n",
    "        correct += len(true_labels) - torch.count_nonzero(pred_class - true_labels)\n",
    "        \n",
    "        ep_loss += loss.detach().item()\n",
    "    print(f'epoch: {ep+1}, loss: {ep_loss / len(train_dataset):.2e}, train acc: {(correct * 100.0) / len(train):.3f}%, time: {(time_s() - start_time):.2f}s')\n",
    "\n",
    "calc_accuracy(student_model)\n",
    "\n",
    "torch.save(student_model.state_dict(), './models/cifar_student.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzItakSaJl7N"
   },
   "source": [
    "# Training Student model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWS2MU0hJ5J2",
    "outputId": "65a5b707-1b2a-42d5-ba92-f6c019a9a8d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 30, 30]             448\n",
      "              ReLU-2           [-1, 16, 30, 30]               0\n",
      "         MaxPool2d-3           [-1, 16, 15, 15]               0\n",
      "            Conv2d-4           [-1, 32, 13, 13]           4,640\n",
      "              ReLU-5           [-1, 32, 13, 13]               0\n",
      "         MaxPool2d-6             [-1, 32, 6, 6]               0\n",
      "           Flatten-7                 [-1, 1152]               0\n",
      "            Linear-8                   [-1, 32]          36,896\n",
      "              ReLU-9                   [-1, 32]               0\n",
      "          Dropout-10                   [-1, 32]               0\n",
      "           Linear-11                   [-1, 10]             330\n",
      "          Softmax-12                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 42,314\n",
      "Trainable params: 42,314\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.35\n",
      "Params size (MB): 0.16\n",
      "Estimated Total Size (MB): 0.52\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create a new model with the last layer removed, provides access to model logits\n",
    "student_model_wo_temperature = torch.nn.Sequential(\n",
    "    *(list(student_model.children())[:-1]),\n",
    "    nn.Softmax(dim=1)\n",
    ").to(device)\n",
    "print(summary(student_model_wo_temperature, (3, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60mXuRlLDFSi",
    "outputId": "a3d5340b-0349-41d4-a9ce-413a39a92d33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 2.16e+00, train acc: 29.550%, time: 7.88s\n",
      "epoch: 2, loss: 2.06e+00, train acc: 40.065%, time: 7.98s\n",
      "epoch: 3, loss: 2.01e+00, train acc: 44.480%, time: 8.01s\n",
      "epoch: 4, loss: 1.99e+00, train acc: 47.342%, time: 8.02s\n",
      "epoch: 5, loss: 1.97e+00, train acc: 49.642%, time: 8.01s\n",
      "epoch: 6, loss: 1.95e+00, train acc: 51.280%, time: 7.89s\n",
      "epoch: 7, loss: 1.93e+00, train acc: 53.015%, time: 7.88s\n",
      "epoch: 8, loss: 1.92e+00, train acc: 54.405%, time: 7.99s\n",
      "epoch: 9, loss: 1.91e+00, train acc: 55.540%, time: 7.81s\n",
      "epoch: 10, loss: 1.89e+00, train acc: 56.842%, time: 7.95s\n",
      "epoch: 11, loss: 1.89e+00, train acc: 57.697%, time: 7.91s\n",
      "epoch: 12, loss: 1.88e+00, train acc: 58.707%, time: 8.05s\n",
      "epoch: 13, loss: 1.87e+00, train acc: 59.577%, time: 7.92s\n",
      "epoch: 14, loss: 1.86e+00, train acc: 60.487%, time: 7.94s\n",
      "epoch: 15, loss: 1.85e+00, train acc: 60.912%, time: 7.98s\n",
      "epoch: 16, loss: 1.84e+00, train acc: 61.837%, time: 7.91s\n",
      "epoch: 17, loss: 1.84e+00, train acc: 62.145%, time: 7.90s\n",
      "epoch: 18, loss: 1.84e+00, train acc: 62.907%, time: 8.01s\n",
      "epoch: 19, loss: 1.83e+00, train acc: 63.540%, time: 7.92s\n",
      "epoch: 20, loss: 1.82e+00, train acc: 63.910%, time: 7.93s\n",
      "test accuracy: 58.770%\n"
     ]
    }
   ],
   "source": [
    "# Training student from scratch using whole dataset\n",
    "student_model_wo_temperature.apply(weight_reset)\n",
    "student_optimizer = torch.optim.Adam(student_model_wo_temperature.parameters(), lr=0.001)\n",
    "student_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "kd_epochs = 20\n",
    "time_s = lambda: time.time()\n",
    "for ep in range(kd_epochs):\n",
    "    ep_loss = 0.0\n",
    "    correct = 0\n",
    "    start_time = time_s()\n",
    "    for i, data in enumerate(train_dataset):\n",
    "        imgs, true_labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        student_optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass of the student\n",
    "        student_output = student_model_wo_temperature(imgs).to(device)\n",
    "\n",
    "        # Calculate loss\n",
    "        student_loss = student_loss_fn(student_output, true_labels)\n",
    "\n",
    "        student_loss.backward()\n",
    "        student_optimizer.step()\n",
    "\n",
    "        pred_class = torch.argmax(student_output, dim=1).to(device)\n",
    "        correct += len(true_labels) - torch.count_nonzero(pred_class - true_labels)\n",
    "        \n",
    "        ep_loss += student_loss.detach().item()\n",
    "    print(f'epoch: {ep+1}, loss: {ep_loss / len(train_dataset):.2e}, train acc: {(correct * 100.0) / len(train):.3f}%, time: {(time_s() - start_time):.2f}s')\n",
    "\n",
    "calc_accuracy(student_model_wo_temperature)\n",
    "\n",
    "torch.save(student_model_wo_temperature.state_dict(), './models/cifar_student_scratch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Ou18ccLKFJL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "kd-cifar.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0078465cbd9f446880ddbee680d4796e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "146b2aec3c83444c8d3cb319347e49d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2e5f050fe8dc457782d0ea2b1d812677": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6bd10102191f4d57b7b29a03d0b774df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9ba0847785674caa983f98654ae6f326",
       "IPY_MODEL_fadfa1710b2b4d46afab50d23c04c30b"
      ],
      "layout": "IPY_MODEL_0078465cbd9f446880ddbee680d4796e"
     }
    },
    "7104988653034cfe90129737fca16688": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ba0847785674caa983f98654ae6f326": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f128a054172c4c52bfaf4e3b10d4c452",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2e5f050fe8dc457782d0ea2b1d812677",
      "value": 1
     }
    },
    "f128a054172c4c52bfaf4e3b10d4c452": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fadfa1710b2b4d46afab50d23c04c30b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7104988653034cfe90129737fca16688",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_146b2aec3c83444c8d3cb319347e49d4",
      "value": " 170500096/? [00:20&lt;00:00, 98127104.37it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
